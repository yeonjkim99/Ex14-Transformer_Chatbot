{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa82599a",
   "metadata": {},
   "source": [
    "# 14-14. 프로젝트: 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48eba3",
   "metadata": {},
   "source": [
    "## Step 0. 환경설정 및 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9922715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd88cf94",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73cd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "# ! ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62085443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 질문 수 : 11824\n",
      "전체 답변 수 : 11824\n",
      "질문 처음 5개\n",
      "['Q', '12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다']\n",
      "질문 끝 5개\n",
      "['훔쳐보는 것도 눈치 보임.', '훔쳐보는 것도 눈치 보임.', '흑기사 해주는 짝남.', '힘든 연애 좋은 연애라는게 무슨 차이일까?', '힘들어서 결혼할까봐']\n",
      "답변 처음 5개\n",
      "['A', '하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.']\n",
      "답변 끝 5개\n",
      "['티가 나니까 눈치가 보이는 거죠!', '훔쳐보는 거 티나나봐요.', '설렜겠어요.', '잘 헤어질 수 있는 사이 여부인 거 같아요.', '도피성 결혼은 하지 않길 바라요.']\n"
     ]
    }
   ],
   "source": [
    "data_file_path = os.getenv('HOME') + '/aiffel/transformer_chatbot/data/'\n",
    "data_file = data_file_path + 'ChatbotData.csv'\n",
    "\n",
    "questions, answers = [], []\n",
    "with open(data_file,'r',encoding=\"utf-8\") as f:\n",
    "    for line in f.read().splitlines():\n",
    "        questions.append(line.split(',')[0:1][0])\n",
    "        answers.append(line.split(',')[1:2][0])\n",
    "\n",
    "print('전체 질문 수 :', len(questions))\n",
    "print('전체 답변 수 :', len(answers))\n",
    "print('질문 처음 5개')\n",
    "print(questions[:5])\n",
    "print('질문 끝 5개')\n",
    "print(questions[-5:])\n",
    "print('답변 처음 5개')\n",
    "print(answers[:5])\n",
    "print('답변 끝 5개')\n",
    "print(answers[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b1d6d",
   "metadata": {},
   "source": [
    "#### 테스트를 위해서 10%의 샘플을 분리해 둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c8004a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 질문 수 : 10641\n",
      "훈련 답변 수 : 10641\n",
      "테스트 질문 수 : 1183\n",
      "테스트 답변 수 : 1183\n"
     ]
    }
   ],
   "source": [
    "questions, test_Q, answers, test_A = train_test_split(questions, answers, test_size=0.1, random_state=32)\n",
    "\n",
    "print('훈련 질문 수 :', len(questions))\n",
    "print('훈련 답변 수 :', len(answers))\n",
    "print('테스트 질문 수 :', len(test_Q))\n",
    "print('테스트 답변 수 :', len(test_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec225a1",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb2bd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 질문 수 : 10640\n",
      "전체 답변 수 : 10640\n",
      "질문 처음 5개\n",
      "['나만 이상해졌어', '썸타는거 친구한테 이야기 한고 싶다.', '내가 생각했던 사람이 맞는지 확신이 안들어', '후폭풍이 올까 두려운데.!', '기차여행 가고 싶어']\n",
      "질문 끝 5개\n",
      "['저 좀 웃게 해주세요', '좋아하는 사람이 부담스러워할까봐 친구들 여럿이서 보는데.', '내가 좋아하는지 그 애가 아예 몰라.', '뭘 챙겨주면 좋을까', '잘 먹는 여자가 좋아']\n",
      "답변 처음 5개\n",
      "['그 말을 한 사람이 가장 이상할 거예요.', '확실해지면 이야기해도 늦지 않아요.', '새로운 모습을 봤나봐요.', '그냥 지금 우세요.', '꿈꾸던 여행이네요.']\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 행 데이터는 column name 이므로 삭제\n",
    "del questions[0]\n",
    "del answers[0]\n",
    "\n",
    "print('전체 질문 수 :', len(questions))\n",
    "print('전체 답변 수 :', len(answers))\n",
    "print('질문 처음 5개')\n",
    "print(questions[:5])\n",
    "print('질문 끝 5개')\n",
    "print(questions[-5:])\n",
    "print('답변 처음 5개')\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9bca6",
   "metadata": {},
   "source": [
    "#### 첫 행이 삭제되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b495ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"여행은 언제나 좋죠.\" => \"여행은 언제나 좋죠 .\"와 같이 한칸 띄움\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'\"', '', sentence)  # 쌍따옴표 \" 제거\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678a7cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리전 : S  이것은 \"컴퓨터\"라고   합니다.    E\n",
      "처리후 : S이것은 컴퓨터라고 합니다 .E\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수 테스트\n",
    "text = '  이것은 \"컴퓨터\"라고   합니다.    '\n",
    "print('처리전 : '+'S'+text+'E')\n",
    "print('처리후 : '+'S'+preprocess_sentence(text)+'E')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfff388",
   "metadata": {},
   "source": [
    "#### 마침표가 본문에서 한칸 떨어졌고, 쌍따옴표(\")가 삭제되었으며, 여러개의 공백이 한개로 합쳐졌고, 문장 앞/뒤의 공백이 삭제되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d996d3",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41797e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "513cc1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb20c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [7568]\n",
      "END_TOKEN의 번호 : [7569]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "203ea19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7570\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9523ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [637, 3308, 4909, 1012]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [1903, 6001, 1, 7358]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54029ad",
   "metadata": {},
   "source": [
    "#### 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd079f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문의 최소 길이 : 1\n",
      "질문의 최대 길이 : 15\n",
      "질문의 평균 길이 : 3.5717105263157896\n",
      "답변의 최소 길이 : 0\n",
      "답변의 최대 길이 : 21\n",
      "답변의 평균 길이 : 3.6795112781954886\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "\n",
    "questions_len = [len(s.split()) for s in questions]\n",
    "answers_len = [len(s.split()) for s in answers]\n",
    "\n",
    "print('질문의 최소 길이 : {}'.format(np.min(questions_len)))\n",
    "print('질문의 최대 길이 : {}'.format(np.max(questions_len)))\n",
    "print('질문의 평균 길이 : {}'.format(np.mean(questions_len)))\n",
    "print('답변의 최소 길이 : {}'.format(np.min(answers_len)))\n",
    "print('답변의 최대 길이 : {}'.format(np.max(answers_len)))\n",
    "print('답변의 평균 길이 : {}'.format(np.mean(answers_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(questions_len)\n",
    "plt.title('questions')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(answers_len)\n",
    "plt.title('answers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbf9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "# 위 boxplot 참조, questions 7, answers 9 중 큰 9를 선택\n",
    "MAX_LENGTH = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76fd9887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 9 이하인 샘플의 비율: 0.9889097744360902\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for s in answers:\n",
    "    if(len(s.split()) <= MAX_LENGTH):\n",
    "        cnt = cnt + 1\n",
    "print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(MAX_LENGTH, (cnt / len(answers))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdae2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # 최대 길이 MAX_LENGTH 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "    # 최대 길이 MAX_LENGTH로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b73ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 7570\n",
      "필터링 후의 질문 샘플 개수: 6916\n",
      "필터링 후의 답변 샘플 개수: 6916\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd013eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d4d1f",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee88769",
   "metadata": {},
   "source": [
    "### 4-1. 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31b81c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4f7a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fa0fa",
   "metadata": {},
   "source": [
    "### 4-2. 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da9c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음은 패딩 마스킹을 구현한 함수입니다.\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323606cc",
   "metadata": {},
   "source": [
    "### 4-3. 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad343168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a63c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de56be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b2638",
   "metadata": {},
   "source": [
    "### 4-4. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6995b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f2d8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f72aa",
   "metadata": {},
   "source": [
    "### 4-5. Transformer 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "def6a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c6947",
   "metadata": {},
   "source": [
    "### 4-6. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f5e4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    2992128     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3519488     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7570)   1945490     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,457,106\n",
      "Trainable params: 8,457,106\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2  # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256   # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 16  # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512     # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.0   # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(vocab_size=VOCAB_SIZE,\n",
    "                    num_layers=NUM_LAYERS,\n",
    "                    units=UNITS,\n",
    "                    d_model=D_MODEL,\n",
    "                    num_heads=NUM_HEADS,\n",
    "                    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f0f99",
   "metadata": {},
   "source": [
    "### 4-7. 손실 함수(Loss function) 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5b9f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412516d",
   "metadata": {},
   "source": [
    "### 4-8. 커스텀 된 학습률(Learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "947ecab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3b22e",
   "metadata": {},
   "source": [
    "### 4-9. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3a16b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01240d31",
   "metadata": {},
   "source": [
    "### 4-10. 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b04488b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "109/109 [==============================] - 9s 25ms/step - loss: 5.9904 - accuracy: 0.1155\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 5.2068 - accuracy: 0.2365\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 4.4761 - accuracy: 0.2372\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 3.9139 - accuracy: 0.2415\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 3.5463 - accuracy: 0.2491\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 3.2860 - accuracy: 0.2625\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 3.0360 - accuracy: 0.2852\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 2.7706 - accuracy: 0.3203\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 2.4731 - accuracy: 0.3620\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 2.1481 - accuracy: 0.4066\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.8061 - accuracy: 0.4571\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.4614 - accuracy: 0.5115\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 1.1325 - accuracy: 0.5695\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.8265 - accuracy: 0.6212\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5670 - accuracy: 0.6619\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3567 - accuracy: 0.6920\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.2125 - accuracy: 0.7078\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.1237 - accuracy: 0.7120\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0792 - accuracy: 0.7127\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0621 - accuracy: 0.7124\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0460 - accuracy: 0.7129\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0475 - accuracy: 0.7121\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0491 - accuracy: 0.7105\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0439 - accuracy: 0.7109\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0432 - accuracy: 0.7106\n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0433 - accuracy: 0.7106\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0411 - accuracy: 0.7108\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0414 - accuracy: 0.7101\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0450 - accuracy: 0.7095\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0427 - accuracy: 0.7100\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0457 - accuracy: 0.7090\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0376 - accuracy: 0.7106\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0444 - accuracy: 0.7096\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0502 - accuracy: 0.7079\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0460 - accuracy: 0.7087\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0402 - accuracy: 0.7101\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0427 - accuracy: 0.7097\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0436 - accuracy: 0.7090\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0409 - accuracy: 0.7097\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0375 - accuracy: 0.7104\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0330 - accuracy: 0.7114\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0350 - accuracy: 0.7107\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0322 - accuracy: 0.7115\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0288 - accuracy: 0.7123\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0259 - accuracy: 0.7126\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0228 - accuracy: 0.7133\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0236 - accuracy: 0.7135\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0219 - accuracy: 0.7139\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0219 - accuracy: 0.7137\n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0221 - accuracy: 0.7137\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555ba3d",
   "metadata": {},
   "source": [
    "### 4-11. 훈련결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2534c5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], 'r')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb2a63",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4f5287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "988c65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5f50f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "질문 입력 : 일이 익숙해 지지 않네\n",
      "정답 출력 : 조금만 더 힘내세요.\n",
      "예측 출력 : 조금만 더 힘내세요.\n",
      "-------------------------\n",
      "질문 입력 : 자꾸 거짓말 하게 되네\n",
      "정답 출력 : 진실된 말을 하려고 노력해보세요.\n",
      "예측 출력 : 선의의 거짓말이길 바라요.\n",
      "-------------------------\n",
      "질문 입력 : 버려줘서 고마워.\n",
      "정답 출력 : 당신이 버렸다고 생각하는 건 어떨까요.\n",
      "예측 출력 : 쉽지 않을 결정이었을 텐데.\n",
      "-------------------------\n",
      "질문 입력 : 옷장이 점점 줄어들어\n",
      "정답 출력 : 지난 계절 옷을 잘 정리해 보세요.\n",
      "예측 출력 : 큰일이네요.\n",
      "-------------------------\n",
      "질문 입력 : 안주 추천 좀\n",
      "정답 출력 : 살 안 찌는 게 좋을 것 같아요.\n",
      "예측 출력 : 힘들겠어요.\n",
      "-------------------------\n",
      "질문 입력 : 스타트업에 가도 될까?\n",
      "정답 출력 : 모 아니면 도예요.\n",
      "예측 출력 : 직접적이든 간접적이든 의사를 확실히 밝혀보세요.\n",
      "-------------------------\n",
      "질문 입력 : 사랑은 영원해?\n",
      "정답 출력 : 사랑은 한 순간이면서 영원한거 같아요.\n",
      "예측 출력 : 믿으면 이루어져요.\n",
      "-------------------------\n",
      "질문 입력 : 술 많이 마셔야지\n",
      "정답 출력 : 적당히 드세요.\n",
      "예측 출력 : 저랑 한 잔 해요.\n",
      "-------------------------\n",
      "질문 입력 : 셀프웨딩이 유행이래\n",
      "정답 출력 : 혼자 준비하기는 조금 벅찰텐대요.\n",
      "예측 출력 : 쉽지 않을거예요.\n",
      "-------------------------\n",
      "질문 입력 : 서류에서 떨어지다니\n",
      "정답 출력 : 합격하는 곳이 있을 거예요.\n",
      "예측 출력 : 될 거예요.\n"
     ]
    }
   ],
   "source": [
    "for i in range(200, 210):\n",
    "    print('-'*25)\n",
    "    print('질문 입력 : {}'.format(test_Q[i]))\n",
    "    print('정답 출력 : {}'.format(test_A[i]))\n",
    "    print('예측 출력 : {}'.format(sentence_generation(test_Q[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b81dcbd",
   "metadata": {},
   "source": [
    "#### 10,640개의 샘플로 3분정도 훈련한 결과치곤 제법 맥락에 맞는 답을 생성하였다. \n",
    "#### 정답으로 제시된 답변과 다르더라도 오히려 더 좋은 답변도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc2cce",
   "metadata": {},
   "source": [
    "## 회고\n",
    "### 이번 프로젝트에서 어려웠던 점\n",
    "\n",
    "Transformer 모델/Attention의 개념은 교재만 읽고는 이해하기가 어렵다. \n",
    "\n",
    "### 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "\n",
    "그 유명한 BERT도 Transformer 모델을 활용하여 사전학습을 적용했다는 사실에 Transformer 모델의 우수성을 알게 되었다.\n",
    "\n",
    "### 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "\n",
    "1. 최대 문장길이를 boxplot을 이용하여 적용했다. Accuracy 향상에 많은 기여를 하였다.\n",
    "2. Hyperparameter인 NUM_LAYERS, D_MODEL, NUM_HEADS, UNITS, DROPOUT등을 다양한 조합으로 바꾸어 보았다.\n",
    "\n",
    "### 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정\n",
    "\n",
    "충분히 달성했다고 생각된다.\n",
    "\n",
    "### 자기 다짐\n",
    "\n",
    "Transformer 모델/Attention의 개념에 대하여 좀 더 공부해야 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4674fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
